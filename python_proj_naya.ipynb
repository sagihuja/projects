{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "python_proj_naya.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqTdkvfJ9TkRhj4D0hyKGn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagihuja/projects/blob/main/python_proj_naya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcUYPgfnD7FY"
      },
      "source": [
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup as bs"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkpODvXzD-mR"
      },
      "source": [
        "\n",
        "def get_article_url(article_id):\n",
        "    \"\"\"\n",
        "    get_article_url is a function that receives the article id and returns its\n",
        "    coresponding Pubmed cited by URL address.\n",
        "    \"\"\"\n",
        "    server = 'https://pubmed.ncbi.nlm.nih.gov/?linkname=pubmed_pubmed_citedin&from_uid='\n",
        "    url = f'{server}{article_id}&page=1'\n",
        "    #print('Link to the article on Pubmed:',url,'\\n')\n",
        "    return url\n",
        "\n",
        "def get_article_html(article_id): \n",
        "    \"\"\"\n",
        "    get_article_html is a function that receives the article id and in return\n",
        "    fetches its coresponding Pubmed HTML file.\n",
        "    \"\"\"     \n",
        "    url = get_article_url(article_id) \n",
        "    r = requests.get(url)\n",
        "    r.raise_for_status()\n",
        "    return r.text\n",
        "\n",
        "def get_cited_amount(article_id):\n",
        "    \"\"\"\n",
        "    This function received the article id and retreives the number of times\n",
        "    it was citated back.\n",
        "    \"\"\"\n",
        "    soup = bs(get_article_html(article_id), 'html5lib')\n",
        "    find_amount = soup.find('span', {\"class\":\"value\"}).get_text()\n",
        "    print('Number of citation found for this article is: ',find_amount)\n",
        "\n",
        "\n",
        "def get_number_citation_pages(article_id):\n",
        "    \"\"\"\n",
        "    This functions retreives internaly from the URL the number of pages\n",
        "    containing citations in order to deal with the pagination, and gather all\n",
        "    the articles.\n",
        "    \"\"\"\n",
        "    soup = bs(get_article_html(article_id), 'html5lib')\n",
        "    find_number_citation_pages = soup.find('label', {\"class\":\"of-total-pages\"}).get_text()\n",
        "    #print(find_number_citation_pages)\n",
        "    number_citating_pages = (find_number_citation_pages.split()[1])\n",
        "    print(number_citating_pages)\n",
        "    value_citating_pages = int(number_citating_pages)\n",
        "        \n",
        "\n",
        "def collect_article_info(article_id):\n",
        "    articles = {}\n",
        "    soup = bs(get_article_html(article_id), 'html5lib')\n",
        "    collect_relevant_article_info = soup.find_all('div', attrs={'class': 'docsum-content'})\n",
        "    #print(collect_relevant_article_info[0].text) #Prints the original article's title, autors and publication information\n",
        "    for line in collect_relevant_article_info:\n",
        "      articles[\"PMID\"] = line.find(\"a\", attrs={'class': 'docsum-title'}).get('data-article-id') \n",
        "      articles[\"Title: \"] = line.find(\"a\", attrs={'class': 'docsum-title'}).text.strip()[:30]\n",
        "      articles[\"Journal name: \"] = line.find(\"span\", attrs={'class': 'docsum-journal-citation short-journal-citation'}).text.strip()\n",
        "      print(\"Articles information: \", articles)\n",
        "\n",
        "\n",
        "def get_journal_impact_factor_url(article_id):\n",
        "    soup = bs(get_article_html(article_id), 'html5lib')\n",
        "    find_journal_name = soup.find_all('span', attrs={'class': 'docsum-journal-citation short-journal-citation'})\n",
        "    #print(find_journal_name[0].text) #Prints the original article journal title as an header\n",
        "    for line in find_journal_name:\n",
        "        journal_name = line.text.split()\n",
        "        #print(journal_name[0:-1])\n",
        "        journal_name_short = '-'.join(journal_name[0:-1])\n",
        "        #print(journal_name_short)\n",
        "        journal_impact_factor_url = (f'https://www.scijournal.org/impact-factor-of-{journal_name_short}shtml')\n",
        "        print(journal_impact_factor_url)\n",
        "\n",
        "        for line in journal_impact_factor_url:\n",
        "            r = requests.get(journal_impact_factor_url)\n",
        "            r.raise_for_status()\n",
        "            #return r.text\n",
        "            soup = bs(get_journal_impact_factor_url(article_id), 'html5lib')\n",
        "            impact_factor = soup.find('div', {\"class\":\"num\"}).get_text()\n",
        "            #impact_factor = soup.find('div', {\"class\":\"num\"}).get_text()\n",
        "            print(impact_factor)\n",
        "\n",
        "\n"
      ],
      "execution_count": 157,
      "outputs": []
    }
  ]
}